import requests
import json
import re
import os
from datetime import datetime
import time
import more_itertools
from concurrent.futures import ThreadPoolExecutor

list = []
a = ""
dtEnd = ""
count = 1


def progress_bar(finish_tasks_number, tasks_number):
  percentage = round(finish_tasks_number / tasks_number * 100)
  process = "\r[%3s%%]: |%-50s|" % (percentage, '|' * (percentage // 2))
  print(process, end='', flush=True)


def Getpage(Gitname):
  url = f'https://gitlab.com/users/{Gitname}/projects.json?page=1&skip_namespace=true&skip_namespace=true'
  r = requests.get(url)
  user_dict = json.loads(r.text)
  htnl = user_dict["html"]

  page_t = re.compile(
    r'<li class="page-item js-pagination-page.*?=true">(?P<page>.*?)</a>',
    re.S)
  page_len = page_t.finditer(htnl)
  page = page_t.finditer(htnl)

  if more_itertools.ilen(page_len) == 0:
    GetPname(
      f"https://gitlab.com/users/{Gitname}/projects.json?page=1&skip_namespace=true&skip_namespace=true",
      Gitname)
  else:
    for page in page:
      page_f = page.group("page")
      url_f = f'https://gitlab.com/users/{Gitname}/projects.json?page={page_f}&skip_namespace=true&skip_namespace=true'
      GetPname(url_f, Gitname)


def GetPname(url_f, Gitname):
  r = requests.get(url_f)
  user_dict1 = json.loads(r.text)
  htnl = user_dict1["html"]

  obj = re.compile(
    r'<span class.*?<span class="project-name">(?P<name>.*?)</span>', re.S)
  p_name_result = obj.finditer(htnl)

  p_time = re.compile(
    r'<span class.*?<span class="project-name">(.*?)</span>.*?datetime="(?P<time>.*?)T(.*?) data-toggle="',
    re.S)
  time_result = p_time.finditer(htnl)
  global list

  for p_name, time_data in zip(p_name_result, time_result):
    p_name1 = p_name.group("name")
    time_data1 = time_data.group("time")
    url_name = f'https://gitlab.com/{Gitname}/{p_name1}/-/archive/main/{p_name1}-main.zip'
    list.append(f'{url_name}+{time_data1}')


def get_time():
  nowtime = datetime.now()
  return nowtime.strftime("%Y-%m-%d")


def downfile(url):
  new_url = url.split('+')[0]
  tem = url.split('/')[-1]
  name = tem.split('+')[0]
  time_d = tem.split('+')[1]
  new_name = name.replace("-main", f'_{time_d}')
  global count

  r = requests.get(new_url)
  with open(f'{a} {dtEnd}/{new_name}', "wb") as f:
    for chunk in r.iter_content(chunk_size=512):
      f.write(chunk)

  shu = count / len(list) * 100
  progress_bar(shu, 100)
  # print(f'{count}-{new_name}完毕')
  count += 1


if __name__ == '__main__':
  name_er = ["rwkgyg", "Misaka-blog"]

  for str in name_er:
    a = str
    dtEnd = get_time()
    folder = f'{a} {dtEnd}'
    if not os.path.exists(folder):
      os.makedirs(folder)
    Getpage(a)
    print(f'获取{a} {len(list)}条项目正在下载........')
    time_start_2 = time.time()

    with ThreadPoolExecutor(5) as t:
      for url in list:
        t.submit(downfile, url)
    time_end_2 = time.time()
    print(f'\n线程池：全部下载完毕,耗时:{(time_end_2 - time_start_2):.2f}秒')
    list = []
    count = 1
